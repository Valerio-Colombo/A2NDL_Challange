{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System checkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 5231\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set GPU memory growth \n",
    "# Allows to only as much GPU memory as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(validation_split=0.2,\n",
    "                                        rotation_range=10,\n",
    "                                        width_shift_range=10,\n",
    "                                        height_shift_range=10,\n",
    "                                        zoom_range=0.3,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        fill_mode='constant',\n",
    "                                        cval=0,\n",
    "                                        rescale=1./255)\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(validation_split=0.2,\n",
    "                                        rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "Found 1247 images belonging to 20 classes.\n",
      "t_len: 39\n",
      "Validation data: \n",
      "Found 307 images belonging to 20 classes.\n",
      "v_len: 10\n"
     ]
    }
   ],
   "source": [
    "# Create generators to read images from dataset directory\n",
    "# -------------------------------------------------------\n",
    "dataset_dir = os.path.join(cwd, 'Classification_Dataset')\n",
    "\n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes=20\n",
    "\n",
    "decide_class_indices = True\n",
    "if decide_class_indices:\n",
    "    classes = ['owl',               #0\n",
    "               'galaxy',            #1\n",
    "               'lightning',         #2\n",
    "               'wine-bottle',       #3\n",
    "               't-shirt',           #4\n",
    "               'waterfall',         #5\n",
    "               'sword',             #6\n",
    "               'school-bus',        #7\n",
    "               'calculator',        #8\n",
    "               'sheet-music',       #9\n",
    "               'airplanes',         #10\n",
    "               'lightbulb',         #11\n",
    "               'skyscraper',        #12\n",
    "               'mountain-bike',     #13\n",
    "               'fireworks',         #14\n",
    "               'computer-monitor',  #15\n",
    "               'bear',              #16\n",
    "               'grand-piano',       #17\n",
    "               'kangaroo',          #18\n",
    "               'laptop']            #19\n",
    "else:\n",
    "    classes=None\n",
    "\n",
    "\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "\n",
    "# Training\n",
    "print(\"Training data: \")\n",
    "train_gen = train_data_gen.flow_from_directory(training_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               classes=classes,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               subset='training',\n",
    "                                               seed=SEED)  # targets are directly converted into one-hot vector\n",
    "print(\"t_len: \" + str(len(train_gen)))\n",
    "\n",
    "# Validation\n",
    "print(\"Validation data: \")\n",
    "valid_gen = train_data_gen.flow_from_directory(training_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               classes=classes,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               subset='validation',\n",
    "                                               seed=SEED)  # targets are directly converted into one-hot vector\n",
    "\n",
    "print(\"v_len: \" + str(len(valid_gen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "# ----------------------\n",
    "\n",
    "# Training\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "test_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 928,612\n",
      "Trainable params: 928,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(img_w, img_h, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# FC layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 39 steps, validate for 10 steps\n",
      "Epoch 1/30\n",
      "39/39 [==============================] - 112s 3s/step - loss: 2.9792 - accuracy: 0.0714 - val_loss: 2.9120 - val_accuracy: 0.1107\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 109s 3s/step - loss: 2.8450 - accuracy: 0.1091 - val_loss: 2.7076 - val_accuracy: 0.2117\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 108s 3s/step - loss: 2.5685 - accuracy: 0.2045 - val_loss: 2.5949 - val_accuracy: 0.2020\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 108s 3s/step - loss: 2.4563 - accuracy: 0.2342 - val_loss: 2.4492 - val_accuracy: 0.2215\n",
      "Epoch 5/30\n",
      "21/39 [===============>..............] - ETA: 43s - loss: 2.3147 - accuracy: 0.2723"
     ]
    }
   ],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x=train_dataset,\n",
    "                    epochs=30,\n",
    "                    steps_per_epoch=len(train_gen),\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=len(valid_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.1, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "fig.show()\n",
    "\n",
    "iterator = iter(train_dataset)\n",
    "\n",
    "for _ in range(1000):\n",
    "    augmented_img, target = next(iterator)\n",
    "    augmented_img = augmented_img[0]   # First element\n",
    "    augmented_img = augmented_img * 255  # denormalize\n",
    "    \n",
    "    plt.imshow(np.uint8(augmented_img))\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
