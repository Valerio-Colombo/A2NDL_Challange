{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfmQXOmnUsrk"
   },
   "outputs": [],
   "source": [
    "google_colab = True\n",
    "if google_colab:\n",
    "  %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "UIrHHSZ2U2y7",
    "outputId": "af9c9f57-8ac4-4c59-d0a8-8279312287a2"
   },
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7GyHn20RVIbU",
    "outputId": "689170f0-b77b-46a8-903a-d2d6ca7f03ea"
   },
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "  !unzip ann-and-dl-image-segmentation.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-6q_K3IKCVx"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oZGJMDuxKCV_",
    "outputId": "241b8bb1-c71a-4c2a-d7e6-64af1f08cfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 8435\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set GPU memory growth\n",
    "# Allows to only as much GPU memory as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2LW8-NMKCWI"
   },
   "source": [
    "# Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qE43FprKCWN"
   },
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    train_img_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                            width_shift_range=10,\n",
    "                                            height_shift_range=10,\n",
    "                                            zoom_range=0.3,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            fill_mode='constant',\n",
    "                                            cval=0,\n",
    "                                            validation_split=0.2,\n",
    "                                            rescale=1./255,)\n",
    "    train_mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                             width_shift_range=10,\n",
    "                                             height_shift_range=10,\n",
    "                                             zoom_range=0.3,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             fill_mode='constant',\n",
    "                                             cval=0,\n",
    "                                             validation_split=0.2,\n",
    "                                             rescale=1./255)\n",
    "else:\n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                            validation_split=0.2)\n",
    "    train_mask_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jWZsKMvMKCWW",
    "outputId": "4ad202ff-50f5-4ec0-cc00-b4acf0835454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6118 images belonging to 1 classes.\n",
      "Found 6118 images belonging to 1 classes.\n",
      "Found 1529 images belonging to 1 classes.\n",
      "Found 1529 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create generators to read images from dataset directory\n",
    "# -------------------------------------------------------\n",
    "dataset_dir = os.path.join(cwd, 'Segmentation_Dataset')\n",
    "\n",
    "# Batch size\n",
    "bs = 16\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "# Training\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None,\n",
    "                                                       shuffle=True,\n",
    "                                                       subset='training',\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       color_mode='rgb',\n",
    "                                                       seed=SEED)  \n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None,\n",
    "                                                         shuffle=True,\n",
    "                                                         subset='training',\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         color_mode='grayscale',\n",
    "                                                         seed=SEED)\n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "\n",
    "# Validation\n",
    "valid_img_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None,\n",
    "                                                       shuffle=False,\n",
    "                                                       subset='validation',\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       color_mode='rgb',\n",
    "                                                       seed=SEED)\n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs, \n",
    "                                                         class_mode=None,\n",
    "                                                         shuffle=False,\n",
    "                                                         subset='validation',\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         color_mode='grayscale',\n",
    "                                                         seed=SEED)\n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFD-5r5JKCWc"
   },
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "# ----------------------\n",
    "\n",
    "# Training\n",
    "# --------\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(tf.expand_dims(y_[..., 0], -1), tf.int32)\n",
    "    return x_, tf.where(y_ > 0, y_ - 1, y_ + 1)\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF_158pGKCW0"
   },
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "### Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSHpAXgbKCW8"
   },
   "outputs": [],
   "source": [
    "# Create Model\n",
    "# ------------\n",
    "\n",
    "def create_model(depth, start_f, num_classes, dynamic_input_shape):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    # -------\n",
    "    for i in range(depth):\n",
    "        \n",
    "        if i == 0:\n",
    "            if dynamic_input_shape:\n",
    "                input_shape = [None, None, 3]\n",
    "            else:\n",
    "                input_shape = [img_h, img_w, 3]\n",
    "        else:\n",
    "            input_shape=[None]\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f, \n",
    "                                         kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         padding='same',\n",
    "                                         input_shape=input_shape))\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "        start_f *= 2\n",
    "\n",
    "    # Decoder\n",
    "    # -------\n",
    "    for i in range(depth):\n",
    "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f // 2,\n",
    "                                         kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         padding='same'))\n",
    "\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "        start_f = start_f // 2\n",
    "\n",
    "    # Prediction Layer\n",
    "    # ----------------\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
    "                                     kernel_size=(1, 1),\n",
    "                                     strides=(1, 1),\n",
    "                                     padding='same',\n",
    "                                     activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "z7zfJj29KCXD",
    "outputId": "ab14df65-d715-4ba5-f27d-0e16e391c42d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 4)       112       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 256, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 8)       296       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        73792     \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        18464     \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 16)        4624      \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 8)       1160      \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 256, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 256, 256, 4)       292       \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 256, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 256, 256, 2)       10        \n",
      "=================================================================\n",
      "Total params: 344,494\n",
      "Trainable params: 344,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(depth=6, \n",
    "                     start_f=4, \n",
    "                     num_classes=2, \n",
    "                     dynamic_input_shape=False)\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCtf9XhvKCXL"
   },
   "source": [
    "## Prepare the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZPy3DnEKCXO"
   },
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) \n",
    "# learning rate\n",
    "lr = 5e-2\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "def my_IoU(y_true, y_pred):\n",
    "    # from probability to predicted class {0, 1}\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
    "\n",
    "    # A and B\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    # A or B\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    # IoU\n",
    "    return intersection / union\n",
    "\n",
    "metrics = [['accuracy', my_IoU]]\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2HKbVm3WKCXU"
   },
   "source": [
    "## Training with callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "colab_type": "code",
    "id": "8eRiB20tKCXW",
    "outputId": "4fcefce0-506e-4057-8af9-9d2defaf3ee6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 383 steps, validate for 96 steps\n",
      "Epoch 1/70\n",
      "383/383 [==============================] - 193s 503ms/step - loss: 0.5452 - accuracy: 0.7427 - my_IoU: 0.7929 - val_loss: 0.4922 - val_accuracy: 0.7455 - val_my_IoU: 0.7458\n",
      "Epoch 2/70\n",
      "383/383 [==============================] - 120s 313ms/step - loss: 0.4843 - accuracy: 0.7432 - my_IoU: 0.7418 - val_loss: 0.4668 - val_accuracy: 0.7438 - val_my_IoU: 0.7126\n",
      "Epoch 3/70\n",
      "383/383 [==============================] - 120s 313ms/step - loss: 0.4613 - accuracy: 0.7694 - my_IoU: 0.7420 - val_loss: 0.4461 - val_accuracy: 0.7916 - val_my_IoU: 0.7440\n",
      "Epoch 4/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.4393 - accuracy: 0.7863 - my_IoU: 0.7473 - val_loss: 0.4269 - val_accuracy: 0.7931 - val_my_IoU: 0.7523\n",
      "Epoch 5/70\n",
      "383/383 [==============================] - 117s 306ms/step - loss: 0.4187 - accuracy: 0.8002 - my_IoU: 0.7470 - val_loss: 0.4102 - val_accuracy: 0.8088 - val_my_IoU: 0.7437\n",
      "Epoch 6/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.4097 - accuracy: 0.8056 - my_IoU: 0.7442 - val_loss: 0.4046 - val_accuracy: 0.8104 - val_my_IoU: 0.7447\n",
      "Epoch 7/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.3939 - accuracy: 0.8154 - my_IoU: 0.7420 - val_loss: 0.3988 - val_accuracy: 0.8107 - val_my_IoU: 0.7415\n",
      "Epoch 8/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.3851 - accuracy: 0.8201 - my_IoU: 0.7414 - val_loss: 0.3771 - val_accuracy: 0.8263 - val_my_IoU: 0.7422\n",
      "Epoch 9/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3804 - accuracy: 0.8236 - my_IoU: 0.7401 - val_loss: 0.3808 - val_accuracy: 0.8246 - val_my_IoU: 0.7378\n",
      "Epoch 10/70\n",
      "383/383 [==============================] - 124s 325ms/step - loss: 0.3698 - accuracy: 0.8291 - my_IoU: 0.7401 - val_loss: 0.3797 - val_accuracy: 0.8267 - val_my_IoU: 0.7431\n",
      "Epoch 11/70\n",
      "383/383 [==============================] - 119s 311ms/step - loss: 0.3598 - accuracy: 0.8353 - my_IoU: 0.7408 - val_loss: 0.3725 - val_accuracy: 0.8294 - val_my_IoU: 0.7431\n",
      "Epoch 12/70\n",
      "383/383 [==============================] - 126s 328ms/step - loss: 0.3544 - accuracy: 0.8385 - my_IoU: 0.7403 - val_loss: 0.3671 - val_accuracy: 0.8369 - val_my_IoU: 0.7410\n",
      "Epoch 13/70\n",
      "383/383 [==============================] - 134s 349ms/step - loss: 0.3515 - accuracy: 0.8402 - my_IoU: 0.7403 - val_loss: 0.3566 - val_accuracy: 0.8376 - val_my_IoU: 0.7402\n",
      "Epoch 14/70\n",
      "383/383 [==============================] - 128s 335ms/step - loss: 0.3447 - accuracy: 0.8441 - my_IoU: 0.7400 - val_loss: 0.3593 - val_accuracy: 0.8367 - val_my_IoU: 0.7354\n",
      "Epoch 15/70\n",
      "383/383 [==============================] - 121s 315ms/step - loss: 0.3443 - accuracy: 0.8440 - my_IoU: 0.7390 - val_loss: 0.3600 - val_accuracy: 0.8394 - val_my_IoU: 0.7403\n",
      "Epoch 16/70\n",
      "383/383 [==============================] - 120s 314ms/step - loss: 0.3403 - accuracy: 0.8467 - my_IoU: 0.7397 - val_loss: 0.3520 - val_accuracy: 0.8427 - val_my_IoU: 0.7373\n",
      "Epoch 17/70\n",
      "383/383 [==============================] - 121s 316ms/step - loss: 0.3369 - accuracy: 0.8480 - my_IoU: 0.7392 - val_loss: 0.3492 - val_accuracy: 0.8446 - val_my_IoU: 0.7414\n",
      "Epoch 18/70\n",
      "383/383 [==============================] - 151s 395ms/step - loss: 0.3313 - accuracy: 0.8511 - my_IoU: 0.7395 - val_loss: 0.3481 - val_accuracy: 0.8441 - val_my_IoU: 0.7388\n",
      "Epoch 19/70\n",
      "383/383 [==============================] - 139s 362ms/step - loss: 0.3331 - accuracy: 0.8504 - my_IoU: 0.7393 - val_loss: 0.3435 - val_accuracy: 0.8448 - val_my_IoU: 0.7412\n",
      "Epoch 20/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3278 - accuracy: 0.8529 - my_IoU: 0.7387 - val_loss: 0.3377 - val_accuracy: 0.8495 - val_my_IoU: 0.7383\n",
      "Epoch 21/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3261 - accuracy: 0.8541 - my_IoU: 0.7387 - val_loss: 0.3425 - val_accuracy: 0.8478 - val_my_IoU: 0.7410\n",
      "Epoch 22/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3245 - accuracy: 0.8554 - my_IoU: 0.7388 - val_loss: 0.3347 - val_accuracy: 0.8522 - val_my_IoU: 0.7408\n",
      "Epoch 23/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3221 - accuracy: 0.8560 - my_IoU: 0.7395 - val_loss: 0.3456 - val_accuracy: 0.8470 - val_my_IoU: 0.7400\n",
      "Epoch 24/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3216 - accuracy: 0.8559 - my_IoU: 0.7382 - val_loss: 0.3359 - val_accuracy: 0.8519 - val_my_IoU: 0.7390\n",
      "Epoch 25/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3193 - accuracy: 0.8577 - my_IoU: 0.7389 - val_loss: 0.3266 - val_accuracy: 0.8549 - val_my_IoU: 0.7391\n",
      "Epoch 26/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3172 - accuracy: 0.8591 - my_IoU: 0.7397 - val_loss: 0.3304 - val_accuracy: 0.8535 - val_my_IoU: 0.7430\n",
      "Epoch 27/70\n",
      "383/383 [==============================] - 120s 313ms/step - loss: 0.3141 - accuracy: 0.8600 - my_IoU: 0.7387 - val_loss: 0.3273 - val_accuracy: 0.8545 - val_my_IoU: 0.7383\n",
      "Epoch 28/70\n",
      "383/383 [==============================] - 119s 311ms/step - loss: 0.3157 - accuracy: 0.8593 - my_IoU: 0.7376 - val_loss: 0.3336 - val_accuracy: 0.8525 - val_my_IoU: 0.7413\n",
      "Epoch 29/70\n",
      "383/383 [==============================] - 121s 315ms/step - loss: 0.3130 - accuracy: 0.8608 - my_IoU: 0.7383 - val_loss: 0.3297 - val_accuracy: 0.8538 - val_my_IoU: 0.7414\n",
      "Epoch 30/70\n",
      "383/383 [==============================] - 120s 315ms/step - loss: 0.3101 - accuracy: 0.8624 - my_IoU: 0.7389 - val_loss: 0.3233 - val_accuracy: 0.8572 - val_my_IoU: 0.7419\n",
      "Epoch 31/70\n",
      "383/383 [==============================] - 122s 318ms/step - loss: 0.3095 - accuracy: 0.8624 - my_IoU: 0.7383 - val_loss: 0.3287 - val_accuracy: 0.8552 - val_my_IoU: 0.7452\n",
      "Epoch 32/70\n",
      "383/383 [==============================] - 122s 319ms/step - loss: 0.3085 - accuracy: 0.8635 - my_IoU: 0.7400 - val_loss: 0.3259 - val_accuracy: 0.8555 - val_my_IoU: 0.7403\n",
      "Epoch 33/70\n",
      "383/383 [==============================] - 122s 317ms/step - loss: 0.3083 - accuracy: 0.8632 - my_IoU: 0.7374 - val_loss: 0.3280 - val_accuracy: 0.8560 - val_my_IoU: 0.7353\n",
      "Epoch 34/70\n",
      "383/383 [==============================] - 122s 318ms/step - loss: 0.3077 - accuracy: 0.8634 - my_IoU: 0.7382 - val_loss: 0.3315 - val_accuracy: 0.8529 - val_my_IoU: 0.7442\n",
      "Epoch 35/70\n",
      "383/383 [==============================] - 119s 311ms/step - loss: 0.3050 - accuracy: 0.8651 - my_IoU: 0.7388 - val_loss: 0.3239 - val_accuracy: 0.8555 - val_my_IoU: 0.7384\n",
      "Epoch 36/70\n",
      "383/383 [==============================] - 117s 307ms/step - loss: 0.3060 - accuracy: 0.8648 - my_IoU: 0.7375 - val_loss: 0.3283 - val_accuracy: 0.8541 - val_my_IoU: 0.7423\n",
      "Epoch 37/70\n",
      "383/383 [==============================] - 121s 316ms/step - loss: 0.3051 - accuracy: 0.8650 - my_IoU: 0.7384 - val_loss: 0.3236 - val_accuracy: 0.8593 - val_my_IoU: 0.7412\n",
      "Epoch 38/70\n",
      "383/383 [==============================] - 120s 314ms/step - loss: 0.3030 - accuracy: 0.8661 - my_IoU: 0.7385 - val_loss: 0.3170 - val_accuracy: 0.8602 - val_my_IoU: 0.7404\n",
      "Epoch 39/70\n",
      "383/383 [==============================] - 119s 311ms/step - loss: 0.3017 - accuracy: 0.8669 - my_IoU: 0.7389 - val_loss: 0.3189 - val_accuracy: 0.8593 - val_my_IoU: 0.7374\n",
      "Epoch 40/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.2999 - accuracy: 0.8673 - my_IoU: 0.7376 - val_loss: 0.3269 - val_accuracy: 0.8553 - val_my_IoU: 0.7294\n",
      "Epoch 41/70\n",
      "383/383 [==============================] - 117s 307ms/step - loss: 0.3003 - accuracy: 0.8674 - my_IoU: 0.7392 - val_loss: 0.3405 - val_accuracy: 0.8467 - val_my_IoU: 0.7490\n",
      "Epoch 42/70\n",
      "383/383 [==============================] - 117s 306ms/step - loss: 0.2996 - accuracy: 0.8679 - my_IoU: 0.7389 - val_loss: 0.3191 - val_accuracy: 0.8603 - val_my_IoU: 0.7389\n",
      "Epoch 43/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.3000 - accuracy: 0.8673 - my_IoU: 0.7379 - val_loss: 0.3230 - val_accuracy: 0.8568 - val_my_IoU: 0.7375\n",
      "Epoch 44/70\n",
      "383/383 [==============================] - 117s 307ms/step - loss: 0.2967 - accuracy: 0.8688 - my_IoU: 0.7379 - val_loss: 0.3232 - val_accuracy: 0.8601 - val_my_IoU: 0.7402\n",
      "Epoch 45/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.2945 - accuracy: 0.8701 - my_IoU: 0.7389 - val_loss: 0.3148 - val_accuracy: 0.8629 - val_my_IoU: 0.7406\n",
      "Epoch 46/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.2966 - accuracy: 0.8689 - my_IoU: 0.7381 - val_loss: 0.3225 - val_accuracy: 0.8581 - val_my_IoU: 0.7359\n",
      "Epoch 47/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.2958 - accuracy: 0.8696 - my_IoU: 0.7374 - val_loss: 0.3188 - val_accuracy: 0.8596 - val_my_IoU: 0.7361\n",
      "Epoch 48/70\n",
      "383/383 [==============================] - 117s 306ms/step - loss: 0.2938 - accuracy: 0.8707 - my_IoU: 0.7387 - val_loss: 0.3186 - val_accuracy: 0.8612 - val_my_IoU: 0.7363\n",
      "Epoch 49/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.2947 - accuracy: 0.8697 - my_IoU: 0.7369 - val_loss: 0.3129 - val_accuracy: 0.8624 - val_my_IoU: 0.7363\n",
      "Epoch 50/70\n",
      "383/383 [==============================] - 118s 309ms/step - loss: 0.2919 - accuracy: 0.8713 - my_IoU: 0.7377 - val_loss: 0.3296 - val_accuracy: 0.8560 - val_my_IoU: 0.7448\n",
      "Epoch 51/70\n",
      "383/383 [==============================] - 119s 309ms/step - loss: 0.2922 - accuracy: 0.8714 - my_IoU: 0.7384 - val_loss: 0.3130 - val_accuracy: 0.8628 - val_my_IoU: 0.7362\n",
      "Epoch 52/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.2902 - accuracy: 0.8728 - my_IoU: 0.7388 - val_loss: 0.3215 - val_accuracy: 0.8588 - val_my_IoU: 0.7343\n",
      "Epoch 53/70\n",
      "383/383 [==============================] - 119s 310ms/step - loss: 0.2925 - accuracy: 0.8710 - my_IoU: 0.7372 - val_loss: 0.3051 - val_accuracy: 0.8654 - val_my_IoU: 0.7384\n",
      "Epoch 54/70\n",
      "383/383 [==============================] - 121s 316ms/step - loss: 0.2924 - accuracy: 0.8712 - my_IoU: 0.7364 - val_loss: 0.3094 - val_accuracy: 0.8652 - val_my_IoU: 0.7386\n",
      "Epoch 55/70\n",
      "383/383 [==============================] - 120s 312ms/step - loss: 0.2900 - accuracy: 0.8723 - my_IoU: 0.7379 - val_loss: 0.3144 - val_accuracy: 0.8603 - val_my_IoU: 0.7336\n",
      "Epoch 56/70\n",
      "383/383 [==============================] - 120s 312ms/step - loss: 0.2899 - accuracy: 0.8724 - my_IoU: 0.7373 - val_loss: 0.3081 - val_accuracy: 0.8649 - val_my_IoU: 0.7341\n",
      "Epoch 57/70\n",
      "383/383 [==============================] - 120s 312ms/step - loss: 0.2878 - accuracy: 0.8736 - my_IoU: 0.7370 - val_loss: 0.3109 - val_accuracy: 0.8635 - val_my_IoU: 0.7335\n",
      "Epoch 58/70\n",
      "383/383 [==============================] - 120s 314ms/step - loss: 0.2902 - accuracy: 0.8726 - my_IoU: 0.7360 - val_loss: 0.3125 - val_accuracy: 0.8619 - val_my_IoU: 0.7343\n",
      "Epoch 59/70\n",
      "383/383 [==============================] - 120s 313ms/step - loss: 0.2885 - accuracy: 0.8731 - my_IoU: 0.7375 - val_loss: 0.3073 - val_accuracy: 0.8653 - val_my_IoU: 0.7395\n",
      "Epoch 60/70\n",
      "383/383 [==============================] - 119s 310ms/step - loss: 0.2897 - accuracy: 0.8725 - my_IoU: 0.7370 - val_loss: 0.3078 - val_accuracy: 0.8658 - val_my_IoU: 0.7367\n",
      "Epoch 61/70\n",
      "383/383 [==============================] - 118s 308ms/step - loss: 0.2880 - accuracy: 0.8729 - my_IoU: 0.7370 - val_loss: 0.3170 - val_accuracy: 0.8633 - val_my_IoU: 0.7406\n",
      "Epoch 62/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.2868 - accuracy: 0.8743 - my_IoU: 0.7374 - val_loss: 0.3106 - val_accuracy: 0.8656 - val_my_IoU: 0.7416\n",
      "Epoch 63/70\n",
      "383/383 [==============================] - 118s 307ms/step - loss: 0.2864 - accuracy: 0.8742 - my_IoU: 0.7371 - val_loss: 0.3123 - val_accuracy: 0.8645 - val_my_IoU: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cdbd0bff60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'segmentation_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=70,\n",
    "          steps_per_epoch=len(train_img_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_img_gen), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7pKaUzDKCXk"
   },
   "source": [
    "## Compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3B_qKpRe91a"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(csv_fname, 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azJB0sa6_wpO"
   },
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktq58wsVKCXm"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import PIL\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Cycle over test images\n",
    "\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "test_img_dir = os.path.join(test_dir, 'images', 'img')\n",
    "\n",
    "img_filenames = next(os.walk(test_img_dir))[2]\n",
    "\n",
    "results={}\n",
    "\n",
    "for img_filename in img_filenames:\n",
    "    \n",
    "    img = Image.open(os.path.join(test_img_dir, img_filename)).convert('RGB')\n",
    "    \n",
    "    img_filename = img_filename[:-4]\n",
    "    img_arr = np.expand_dims(np.array(img), 0)\n",
    "    img_arr = img_arr / 255.0\n",
    "    out_softmax = model.predict(x=img_arr)\n",
    "\n",
    "    # Get predicted class as the index corresponding to the maximum value in the vector probability\n",
    "    predicted_class = tf.argmax(out_softmax, -1)\n",
    "    predicted_class = predicted_class[0]\n",
    "    prediction_img = np.zeros([256, 256, 1])\n",
    "    prediction_img[np.where(predicted_class == 0)] = 1\n",
    "    prediction_img[np.where(predicted_class == 1)] = 0\n",
    "    results[img_filename] = rle_encode(prediction_img)\n",
    "\n",
    "create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CNN_Segmentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TensorFlowEnv",
   "language": "python",
   "name": "tensorflowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
