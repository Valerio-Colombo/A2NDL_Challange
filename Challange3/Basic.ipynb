{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom datetime import datetime\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models, utils","execution_count":31,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## System checkup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the seed for random operations. \n# This let our experiments to be reproducible. \nSEED = 5231\ntf.random.set_seed(SEED)  \n\n# Get current working directory\nkaggle = True\nif kaggle:\n    cwd = os.path.join('../input/ann-and-dl-vqa')\nelse:\n    cwd = os.getcwd()\n\n# Set GPU memory growth \n# Allows to only as much GPU memory as needed\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","execution_count":32,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Batch size\nbs = 6\n\n# Validation size\nval_size = 0.2\n\n# img shape\nimg_w = 480\nimg_h = 320\n\n# question shape\nq_len = 100\n\n# dictionary var\nMAX_NUM_QUESTIONS = 5000\nMAX_NUM_WORDS = 20000\n\n# class shape\nnum_classes=13\nclasses = ['0',     #0\n           '1',     #1\n           '10',    #2\n           '2',     #3\n           '3',     #4\n           '4',     #5\n           '5',     #6\n           '6',     #7\n           '7',     #8\n           '8',     #9\n           '9',     #10\n           'no',    #11\n           'yes']   #12","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ndataset_dir = os.path.join(cwd, 'dataset_vqa')\n\nquestions = [] # Array containing all training and validation questions\nquestions_test = []  # Array containing all test questions\ntrain_data = [] # Array containing all training {question, image, answer} dict\nvalid_data = [] # Array containing all validation {question, image, answer} dict\ntest_data = [] # Array containing all test {question_id, image_filename, question} dict\n\nwith open(dataset_dir + '/train_data.json', 'r') as f:\n    train_d = json.load(f)[\"questions\"]\n    if(MAX_NUM_QUESTIONS < len(train_d)):\n        train_d = train_d[:MAX_NUM_QUESTIONS]\n    questions = [e['question'] for e in train_d]\n    valid_data = train_d[:int(len(train_d)*val_size)]\n    train_data = train_d[int(len(train_d)*val_size):]\n    print('Train questions: ' + str(len(train_data)))\n    print('Validation questions: ' + str(len(valid_data)))\n\nwith open(dataset_dir + '/test_data.json', 'r') as f:\n    test_data = json.load(f)[\"questions\"]\n    questions_test= [e['question'] for e in test_data]\n    print('Test questions: ' + str(len(test_data)))    \n    \n#print(questions[:10])\nf.close()","execution_count":34,"outputs":[{"output_type":"stream","text":"Train questions: 4000\nValidation questions: 1000\nTest questions: 3000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nquestions_all = questions + questions_test\n\n# Create Tokenizer to convert words to integers\nq_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\nq_tokenizer.fit_on_texts(questions_all)\nq_tokenized = q_tokenizer.texts_to_sequences(questions_all)\n\nq_wtoi = q_tokenizer.word_index\nprint('Total question words:', len(q_wtoi))\n\nmax_q_length = max(len(sentence) for sentence in q_tokenized)\nprint('Max question length:', max_q_length)","execution_count":35,"outputs":[{"output_type":"stream","text":"Total question words: 70\nMax question length: 39\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pad to max question length\nq_encoder_inputs = pad_sequences(q_tokenized, maxlen=max_q_length)\nprint(\"Question encoder inputs shape:\", q_encoder_inputs.shape)\n\nq_encoder_inputs_train = q_encoder_inputs[int(len(train_d)*val_size):int(len(train_d))]\nq_encoder_inputs_valid = q_encoder_inputs[:int(len(train_d)*val_size)]\nq_encoder_inputs_test = q_encoder_inputs[:int(len(train_d))]","execution_count":36,"outputs":[{"output_type":"stream","text":"Question encoder inputs shape: (8000, 39)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom data generator\n# data: json file with (question, image_name, answer) tuples\n# batch_size: size of batches\nimport math\nfrom skimage.io import imread\n\nclass VQASequence(utils.Sequence):\n        def __init__(self, data, q, batch_size):\n            self.x = list(zip([e['image_filename'] for e in data], q)) # [image_name, question]\n            self.y = [classes.index(e['answer']) for e in data] # target classes\n            self.batch_size = batch_size\n\n        def __len__(self):\n            return math.ceil(len(self.y) / self.batch_size)\n        \n        def __getitem__(self, idx):\n            batch_x = self.x[idx*self.batch_size : (idx + 1)*self.batch_size]\n            batch_y = self.y[idx*self.batch_size : (idx + 1)*self.batch_size]\n\n            return [np.array([self.__imgtoarray__(e[0]) for e in batch_x]), np.array([e[1] for e in batch_x])], np.array(batch_y)\n        \n        def __imgtoarray__(self, img):\n            if kaggle:\n                im = Image.open('/kaggle/input/ann-and-dl-vqa/dataset_vqa/train/'+img).convert('RGB')\n            else:\n                im = Image.open('dataset_vqa/train/'+img).convert('RGB')\n            np_im = np.array(im)\n            #print(np_im.shape)\n            return np_im/255.0\n        \nclass VQASequenceTest(utils.Sequence):\n        def __init__(self, data, q, batch_size):\n            self.x = list(zip([e['image_filename'] for e in data], q)) # [image_name, question]\n            self.y = [0 for e in data] # target classes\n            self.batch_size = batch_size\n\n        def __len__(self):\n            return math.ceil(len(self.y) / self.batch_size)\n        \n        def __getitem__(self, idx):\n            batch_x = self.x[idx*self.batch_size : (idx + 1)*self.batch_size]\n            batch_y = self.y[idx*self.batch_size : (idx + 1)*self.batch_size]\n\n            return [np.array([self.__imgtoarray__(e[0]) for e in batch_x]), np.array([e[1] for e in batch_x])], np.array(batch_y)\n        \n        def __on_epoch_end__(self):\n            print('end')\n        \n        def __imgtoarray__(self, img):\n            if kaggle:\n                im = Image.open('/kaggle/input/ann-and-dl-vqa/dataset_vqa/train/'+img).convert('RGB')\n            else:\n                im = Image.open('dataset_vqa/train/'+img).convert('RGB')\n            np_im = np.array(im)\n            #print(np_im.shape)\n            return np_im/255.0\n            ","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vqa_generator_train = VQASequence(train_data, q_encoder_inputs_train, bs)\nvqa_generator_valid = VQASequence(valid_data, q_encoder_inputs_valid, bs)\nvqa_generator_test = VQASequenceTest(test_data, q_encoder_inputs_test, bs)\n#print(vqa_generator_train.__getitem__(0))","execution_count":53,"outputs":[{"output_type":"stream","text":"([array([[[[0.41568627, 0.41568627, 0.41568627],\n         [0.41176471, 0.41176471, 0.40784314],\n         [0.41176471, 0.41176471, 0.41176471],\n         ...,\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39607843]],\n\n        [[0.41176471, 0.40784314, 0.40784314],\n         [0.41176471, 0.41176471, 0.41176471],\n         [0.41176471, 0.41176471, 0.40784314],\n         ...,\n         [0.4       , 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.40392157, 0.40392157, 0.4       ]],\n\n        [[0.41176471, 0.41176471, 0.41176471],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41176471, 0.41176471, 0.41176471],\n         ...,\n         [0.4       , 0.4       , 0.4       ],\n         [0.40784314, 0.40784314, 0.40392157],\n         [0.4       , 0.4       , 0.4       ]],\n\n        ...,\n\n        [[0.46666667, 0.4627451 , 0.45882353],\n         [0.4627451 , 0.4627451 , 0.45882353],\n         [0.4627451 , 0.4627451 , 0.45882353],\n         ...,\n         [0.61960784, 0.60784314, 0.58823529],\n         [0.61960784, 0.60784314, 0.58823529],\n         [0.61960784, 0.60784314, 0.58823529]],\n\n        [[0.46666667, 0.4627451 , 0.45882353],\n         [0.4627451 , 0.45882353, 0.45490196],\n         [0.47058824, 0.46666667, 0.4627451 ],\n         ...,\n         [0.61960784, 0.60784314, 0.58823529],\n         [0.61960784, 0.60784314, 0.59215686],\n         [0.61960784, 0.60784314, 0.58823529]],\n\n        [[0.4627451 , 0.45882353, 0.45490196],\n         [0.46666667, 0.4627451 , 0.45882353],\n         [0.4627451 , 0.45882353, 0.45490196],\n         ...,\n         [0.61960784, 0.60784314, 0.58823529],\n         [0.61960784, 0.60784314, 0.58823529],\n         [0.61960784, 0.60784314, 0.58823529]]],\n\n\n       [[[0.41960784, 0.41960784, 0.41568627],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.4       , 0.4       , 0.4       ],\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39607843]],\n\n        [[0.41568627, 0.41176471, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39215686],\n         [0.4       , 0.4       , 0.4       ]],\n\n        [[0.41568627, 0.41568627, 0.41568627],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.4       , 0.4       , 0.39607843],\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.4       , 0.4       , 0.4       ]],\n\n        ...,\n\n        [[0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.46666667],\n         [0.4745098 , 0.47058824, 0.46666667],\n         ...,\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56470588, 0.55294118, 0.54117647],\n         [0.56078431, 0.55294118, 0.5372549 ]],\n\n        [[0.47058824, 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         [0.4745098 , 0.4745098 , 0.46666667],\n         ...,\n         [0.56470588, 0.55686275, 0.54117647],\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56078431, 0.55294118, 0.5372549 ]],\n\n        [[0.47058824, 0.46666667, 0.4627451 ],\n         [0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         ...,\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56470588, 0.55294118, 0.5372549 ]]],\n\n\n       [[[0.41960784, 0.41960784, 0.41568627],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.4       , 0.4       , 0.4       ],\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39607843]],\n\n        [[0.41568627, 0.41176471, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39215686],\n         [0.4       , 0.4       , 0.4       ]],\n\n        [[0.41568627, 0.41568627, 0.41568627],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.4       , 0.4       , 0.39607843],\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.4       , 0.4       , 0.4       ]],\n\n        ...,\n\n        [[0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.46666667],\n         [0.4745098 , 0.47058824, 0.46666667],\n         ...,\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56470588, 0.55294118, 0.54117647],\n         [0.56078431, 0.55294118, 0.5372549 ]],\n\n        [[0.47058824, 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         [0.4745098 , 0.4745098 , 0.46666667],\n         ...,\n         [0.56470588, 0.55686275, 0.54117647],\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56078431, 0.55294118, 0.5372549 ]],\n\n        [[0.47058824, 0.46666667, 0.4627451 ],\n         [0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         ...,\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56470588, 0.55294118, 0.5372549 ]]],\n\n\n       [[[0.41960784, 0.41960784, 0.41568627],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.4       , 0.4       , 0.4       ],\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39607843]],\n\n        [[0.41568627, 0.41176471, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.39607843, 0.39607843, 0.39607843],\n         [0.39607843, 0.39607843, 0.39215686],\n         [0.4       , 0.4       , 0.4       ]],\n\n        [[0.41568627, 0.41568627, 0.41568627],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         ...,\n         [0.4       , 0.4       , 0.39607843],\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.4       , 0.4       , 0.4       ]],\n\n        ...,\n\n        [[0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.46666667],\n         [0.4745098 , 0.47058824, 0.46666667],\n         ...,\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56470588, 0.55294118, 0.54117647],\n         [0.56078431, 0.55294118, 0.5372549 ]],\n\n        [[0.47058824, 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         [0.4745098 , 0.4745098 , 0.46666667],\n         ...,\n         [0.56470588, 0.55686275, 0.54117647],\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56078431, 0.55294118, 0.5372549 ]],\n\n        [[0.47058824, 0.46666667, 0.4627451 ],\n         [0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         ...,\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56078431, 0.55294118, 0.5372549 ],\n         [0.56470588, 0.55294118, 0.5372549 ]]],\n\n\n       [[[0.41960784, 0.41960784, 0.41960784],\n         [0.41176471, 0.41176471, 0.41176471],\n         [0.41960784, 0.41960784, 0.41568627],\n         ...,\n         [0.40784314, 0.40784314, 0.40784314],\n         [0.4       , 0.4       , 0.4       ],\n         [0.40392157, 0.40392157, 0.40392157]],\n\n        [[0.41176471, 0.41176471, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         [0.41176471, 0.41176471, 0.41176471],\n         ...,\n         [0.4       , 0.4       , 0.4       ],\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.40392157, 0.40392157, 0.40392157]],\n\n        [[0.40784314, 0.40784314, 0.40784314],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41176471, 0.41176471, 0.41176471],\n         ...,\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.41176471, 0.41176471, 0.41176471],\n         [0.40392157, 0.40392157, 0.40392157]],\n\n        ...,\n\n        [[0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         [0.4745098 , 0.47058824, 0.46666667],\n         ...,\n         [0.57254902, 0.56078431, 0.54509804],\n         [0.57254902, 0.56078431, 0.54509804],\n         [0.56862745, 0.56078431, 0.54509804]],\n\n        [[0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.46666667, 0.4627451 ],\n         [0.47843137, 0.4745098 , 0.47058824],\n         ...,\n         [0.57254902, 0.56470588, 0.54509804],\n         [0.56862745, 0.56078431, 0.54509804],\n         [0.56862745, 0.56078431, 0.54509804]],\n\n        [[0.47058824, 0.47058824, 0.4627451 ],\n         [0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         ...,\n         [0.56862745, 0.55686275, 0.54117647],\n         [0.56862745, 0.56078431, 0.54117647],\n         [0.56862745, 0.56078431, 0.54509804]]],\n\n\n       [[[0.41960784, 0.41960784, 0.41960784],\n         [0.41176471, 0.41176471, 0.41176471],\n         [0.41960784, 0.41960784, 0.41568627],\n         ...,\n         [0.40784314, 0.40784314, 0.40784314],\n         [0.4       , 0.4       , 0.4       ],\n         [0.40392157, 0.40392157, 0.40392157]],\n\n        [[0.41176471, 0.41176471, 0.41176471],\n         [0.41568627, 0.41568627, 0.41568627],\n         [0.41176471, 0.41176471, 0.41176471],\n         ...,\n         [0.4       , 0.4       , 0.4       ],\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.40392157, 0.40392157, 0.40392157]],\n\n        [[0.40784314, 0.40784314, 0.40784314],\n         [0.41568627, 0.41568627, 0.41176471],\n         [0.41176471, 0.41176471, 0.41176471],\n         ...,\n         [0.40392157, 0.40392157, 0.40392157],\n         [0.41176471, 0.41176471, 0.41176471],\n         [0.40392157, 0.40392157, 0.40392157]],\n\n        ...,\n\n        [[0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         [0.4745098 , 0.47058824, 0.46666667],\n         ...,\n         [0.57254902, 0.56078431, 0.54509804],\n         [0.57254902, 0.56078431, 0.54509804],\n         [0.56862745, 0.56078431, 0.54509804]],\n\n        [[0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.46666667, 0.4627451 ],\n         [0.47843137, 0.4745098 , 0.47058824],\n         ...,\n         [0.57254902, 0.56470588, 0.54509804],\n         [0.56862745, 0.56078431, 0.54509804],\n         [0.56862745, 0.56078431, 0.54509804]],\n\n        [[0.47058824, 0.47058824, 0.4627451 ],\n         [0.4745098 , 0.47058824, 0.46666667],\n         [0.47058824, 0.47058824, 0.4627451 ],\n         ...,\n         [0.56862745, 0.55686275, 0.54117647],\n         [0.56862745, 0.56078431, 0.54117647],\n         [0.56862745, 0.56078431, 0.54509804]]]]), array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        14, 15, 34, 19, 59,  3,  4],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0, 12, 13,  2, 10,  3, 16, 19, 60, 25, 23,\n        20, 10, 40,  2,  1, 33, 51],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  4, 64, 65,  9,  7,\n         1,  5, 48,  6,  1, 20, 53],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 14, 15, 10,\n         3, 18, 20, 37, 25, 33, 10],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  4, 21, 24, 11,  9,  7,\n         1,  5, 46,  6,  1, 32, 26],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  3,  4, 21, 33, 29, 37]], dtype=int32)], array([ 1,  4, 12,  3, 11, 11]))\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotImages(question_arr, subset):\n    num = len(question_arr)\n    fig, axes = plt.subplots(num, 1, figsize=(30,30))\n    axes = axes.flatten()\n    for q, ax in zip(question_arr, axes):\n        img = Image.open(dataset_dir + '/' + subset + '/' + q[\"image_filename\"])\n        ax.imshow(img)\n        ax.set_title(q[\"question\"])\n        ax.axis('off')\n  \n    plt.show()","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotImages(train_data[:2], 'train')\n#plotImages(test_data[:2], 'test')","execution_count":40,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNN for image encoding\n\n# Load VGG16 Model\nvgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n\nfinetuning = False\n\nif finetuning:\n    freeze_until = 15 # layer from which we want to fine-tune\n    \n    for layer in vgg.layers[:freeze_until]:\n        layer.trainable = False\nelse:\n    vgg.trainable = False\n\n# Image encoding\nimage_model = models.Sequential()\nimage_model.add(vgg)\nimage_model.add(layers.Flatten())\n\nimage_input = layers.Input(shape=(img_h, img_w, 3))\n\nencoded_image = image_model(image_input)\n#encoded_image = image_model","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RNN for question encoding\n\nquestion_input = layers.Input(shape=[max_q_length])\nembedded_question = layers.Embedding(input_dim=len(q_wtoi)+1, output_dim=10, input_length=max_q_length)(question_input)\nencoded_question = layers.LSTM(128)(embedded_question)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine CNN and RNN to create the final model\nmerged = layers.concatenate([encoded_question, encoded_image])\noutput = layers.Dense(num_classes, activation='softmax')(merged)\nvqa_model = models.Model(inputs=[image_input, question_input], outputs=output)\n\nvqa_model.summary()","execution_count":43,"outputs":[{"output_type":"stream","text":"Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_9 (InputLayer)            [(None, 39)]         0                                            \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 39, 10)       710         input_9[0][0]                    \n__________________________________________________________________________________________________\ninput_8 (InputLayer)            [(None, 320, 480, 3) 0                                            \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   (None, 128)          71168       embedding_2[0][0]                \n__________________________________________________________________________________________________\nsequential_2 (Sequential)       (None, 76800)        14714688    input_8[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 76928)        0           lstm_2[0][0]                     \n                                                                 sequential_2[1][0]               \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 13)           1000077     concatenate_2[0][0]              \n==================================================================================================\nTotal params: 15,786,643\nTrainable params: 1,071,955\nNon-trainable params: 14,714,688\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cwd = os.getcwd()\n\n# Create a folder which will contain the result of all the run of the network\nexps_dir = os.path.join(cwd, 'classification_experiments')\nif not os.path.exists(exps_dir):\n    os.makedirs(exps_dir)\n\nnow = datetime.now().strftime('%b%d_%H-%M-%S')\n\nmodel_name = 'CNN'\n\n# Create a folder which will contain the result of callbacks of a singular execution\nexp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\nif not os.path.exists(exp_dir):\n    os.makedirs(exp_dir)\n    \ncallbacks = []\n\n# Callback1 - Model checkpoint\nckpt = False\n\nif ckpt:\n    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n    if not os.path.exists(ckpt_dir):\n        os.makedirs(ckpt_dir)\n\n    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n                                                       save_weights_only=True) # False to save the model directly\n    callbacks.append(ckpt_callback)\n\n# Callback2 - Early Stopping\nearly_stop = True\n\nif early_stop:\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n    callbacks.append(es_callback)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimization params\nepoch_num = 100\n\n# Loss\nloss = tf.keras.losses.SparseCategoricalCrossentropy()\n\n# Optimazer\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)\n\n# Validation metrics\nmetrics = ['accuracy']\n\n# Compile Model\nvqa_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = vqa_model.fit_generator(generator = vqa_generator_train,\n                                  callbacks=callbacks,\n                                  epochs=epoch_num,\n                                  steps_per_epoch=vqa_generator_train.__len__(),\n                                  validation_data= vqa_generator_valid,\n                                  validation_steps=vqa_generator_valid.__len__())","execution_count":46,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'dataset_vqa/train/CLEVR_train_000264.png'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-811d04c10460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvqa_generator_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvqa_generator_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                   validation_steps=vqa_generator_valid.__len__())\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m   def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, shuffle, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     (peek, wrap_in_tuple, elements_to_keep, partial_sample_weight,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-495d0174fde9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__imgtoarray__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__imgtoarray__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-495d0174fde9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__imgtoarray__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__imgtoarray__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-495d0174fde9>\u001b[0m in \u001b[0;36m__imgtoarray__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__imgtoarray__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_vqa/train/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mnp_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#print(np_im.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_vqa/train/CLEVR_train_000264.png'"]}]},{"metadata":{},"cell_type":"markdown","source":"## Predict"},{"metadata":{"trusted":false},"cell_type":"code","source":"from datetime import datetime\n\ndef create_csv(results, results_dir='./Test_Result'):\n\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"prediction = vqa_model.predict_generator(vqa_generator_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"prediction_argmax = []\n\nfor e in prediction:\n    prediction_argmax.append(np.argmax(e))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"i=0\n\nresults = {}\n\nwhile(i<len(prediction)):\n    results[str(i)] = prediction_argmax[i]\n    i+=1\n\ncreate_csv(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"TensorFlowEnv","language":"python","name":"tensorflowenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}